{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_Race.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1BBnXje2itr"
      },
      "source": [
        "## 環境\r\n",
        "Pytourchの環境設定、Pythonライブラリの設定などを行う。Google Colabデフォルトのpytorchのバージョンを確認して、違ったら念のため高田さんのJetson nano環境へ合わせる。\r\n",
        "\r\n",
        "この処理不要かも。学習データをtrt形式に変更後、うまく動けば環境を合わせる必要なし。後で検証する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqVPZ-IB9-yB",
        "outputId": "cd4fdae1-1e96-4c45-b605-dc6cb44538e2"
      },
      "source": [
        "!python3 -c 'import torch; print(torch.__version__) '\r\n",
        "!python3 -c 'import torchvision; print(torchvision.__version__) '"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.7.0+cu101\n",
            "0.8.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwc_z017_eha",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52e12cb2-59a9-40f8-9e4e-efa2b730f1a6"
      },
      "source": [
        "!pip uninstall torch\r\n",
        "!pip uninstall torchvision\r\n",
        "!pip install torch===1.4.0 torchvision===0.5.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling torch-1.7.0+cu101:\n",
            "  Would remove:\n",
            "    /usr/local/bin/convert-caffe2-to-onnx\n",
            "    /usr/local/bin/convert-onnx-to-caffe2\n",
            "    /usr/local/lib/python3.6/dist-packages/caffe2/*\n",
            "    /usr/local/lib/python3.6/dist-packages/torch-1.7.0+cu101.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled torch-1.7.0+cu101\n",
            "Uninstalling torchvision-0.8.1+cu101:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision-0.8.1+cu101.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision.libs/libcudart.c740f4ef.so.10.1\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision.libs/libjpeg.ceea7512.so.62\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision.libs/libpng16.7f72a3c5.so.16\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision.libs/libz.1328edc3.so.1\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled torchvision-0.8.1+cu101\n",
            "Collecting torch===1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/19/4804aea17cd136f1705a5e98a00618cb8f6ccc375ad8bfa437408e09d058/torch-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (753.4MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4MB 15kB/s \n",
            "\u001b[?25hCollecting torchvision===0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/90/6141bf41f5655c78e24f40f710fdd4f8a8aff6c8b7c6f0328240f649bdbe/torchvision-0.5.0-cp36-cp36m-manylinux1_x86_64.whl (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 56.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision===0.5.0) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision===0.5.0) (1.19.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision===0.5.0) (1.15.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "Successfully installed torch-1.4.0 torchvision-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVOXk237FrtQ"
      },
      "source": [
        "versionの確認およびGPU使用可能か確認する。TureならGPU使用可能。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4N_4APOAVgc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2417bf9-8709-4a6a-e0ad-8b5399e7af7e"
      },
      "source": [
        "!python3 -c 'import torch; print(torch.__version__) '\r\n",
        "!python3 -c 'import torchvision; print(torchvision.__version__) '\r\n",
        "import torch\r\n",
        "print(torch.cuda.is_available())\r\n",
        "torch.cuda.current_device()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.4.0\n",
            "0.5.0\n",
            "True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTtcSZbD3Ftx"
      },
      "source": [
        "## Google Driveマウント\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsN1tXiN3S6j",
        "outputId": "955cdab4-c677-4e23-a6b2-45ed07bc964b"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PO05CeDzI4SO"
      },
      "source": [
        "作業ディレクトリに移動する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FArUJdB3lhe",
        "outputId": "33775d71-66cc-433b-805a-2d9eda235ccf"
      },
      "source": [
        "cd drive/My Drive/Colab Notebooks/AI_Race"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/AI_Race\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDiIVDfk35Q-"
      },
      "source": [
        "## Gitクローン\r\n",
        "~~必要に応じてgitから環境をクローンする。まずは初回だけ。~~\r\n",
        "ai_race/ai_race/learning/scripts直下のファイルがあればOKだと思われる。以下はseigotからフォークしたものをすべてGoogleDrive上にクローンしてしまった例。\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPj80OEz4JH8"
      },
      "source": [
        "# !git clone https://github.com/iwatadive28/ai_race.git"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abDPCBSF5RvW"
      },
      "source": [
        "#Train実行\r\n",
        "スクリプト直下まで移動してtrain.pyを実行してみる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2n4xDgD5dzj",
        "outputId": "90bcef2e-1a3f-4e8c-bd79-98ca7d512848"
      },
      "source": [
        "cd ai_race/ai_race/learning/scripts"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/AI_Race/ai_race/ai_race/learning/scripts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOu3Fn9HIEUx"
      },
      "source": [
        "## Train実行\r\n",
        "作業ディレクトリ直下まで移動。ここではtrain.pyと同等の処理を小分けにして行う。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gr9vSbQF4Ypi"
      },
      "source": [
        "### モジュールのインポート"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1piIsFnx4oUC"
      },
      "source": [
        "'''Train CIFAR10 with PyTorch.'''\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.backends.cudnn as cudnn\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torchvision.models as models\r\n",
        "\r\n",
        "import os\r\n",
        "import io\r\n",
        "import argparse\r\n",
        "import pandas as pd\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from MyDataSet import MyDataset"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLnpuItw4rEy"
      },
      "source": [
        "### train関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPL62aTM4m05"
      },
      "source": [
        "def train(model, device, train_loader, criterion, optimizer):\r\n",
        "\tmodel.train()\r\n",
        "\r\n",
        "\toutput_list = []\r\n",
        "\ttarget_list = []\r\n",
        "\trunning_loss = 0.0\r\n",
        "\tfor batch_idx, (inputs, targets) in enumerate(train_loader):\r\n",
        "\t\t# Forward processing.\r\n",
        "\t\tinputs, targets = inputs.to(device), targets.to(device)\r\n",
        "\t\toutputs = model(inputs)\r\n",
        "\t\tloss = criterion(outputs, targets)\r\n",
        "\r\n",
        "\t\t# Backward processing.\r\n",
        "\t\toptimizer.zero_grad()\r\n",
        "\t\tloss.backward()\r\n",
        "\t\toptimizer.step()\r\n",
        "\r\n",
        "\t\t# Set data to calculate score.\r\n",
        "\t\toutput_list += [int(o.argmax()) for o in outputs]\r\n",
        "\t\ttarget_list += [int(t) for t in targets]\r\n",
        "\t\trunning_loss += loss.item()\r\n",
        "\r\n",
        "\t\t# Calculate score at present.\r\n",
        "\t\ttrain_acc, train_loss = calc_score(output_list, target_list, running_loss, train_loader)\r\n",
        "\t\tif batch_idx % 10 == 0 and batch_idx != 0:\r\n",
        "\t\t\tstdout_temp = 'batch: {:>3}/{:<3}, train acc: {:<8}, train loss: {:<8}'\r\n",
        "\t\t\tprint(stdout_temp.format(batch_idx, len(train_loader), train_acc, train_loss))\r\n",
        "\r\n",
        "\t# Calculate score.\r\n",
        "\ttrain_acc, train_loss = calc_score(output_list, target_list, running_loss, train_loader)\r\n",
        "\r\n",
        "\treturn train_acc, train_loss"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVXh4-ep451K"
      },
      "source": [
        "### test関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4gX_hKX4-a7"
      },
      "source": [
        "def test(model, device, test_loader, criterion):\r\n",
        "\tmodel.eval()\r\n",
        "\r\n",
        "\toutput_list = []\r\n",
        "\ttarget_list = []\r\n",
        "\trunning_loss = 0.0\r\n",
        "\tfor batch_idx, (inputs, targets) in enumerate(test_loader):\r\n",
        "\t\t# Forward processing.\r\n",
        "\t\tinputs, targets = inputs.to(device), targets.to(device)\r\n",
        "\t\toutputs = model(inputs)\r\n",
        "\t\tloss = criterion(outputs, targets)\r\n",
        "\t\t\r\n",
        "\t\t# Set data to calculate score.\r\n",
        "\t\toutput_list += [int(o.argmax()) for o in outputs]\r\n",
        "\t\ttarget_list += [int(t) for t in targets]\r\n",
        "\t\trunning_loss += loss.item()\r\n",
        "\t\t\r\n",
        "\ttest_acc, test_loss = calc_score(output_list, target_list, running_loss, test_loader)\r\n",
        "\r\n",
        "\treturn test_acc, test_loss"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp1KJZor4_gn"
      },
      "source": [
        "def calc_score(output_list, target_list, running_loss, data_loader):\r\n",
        "\t# Calculate accuracy.\r\n",
        "\t#result = classification_report(output_list, target_list) #, output_dict=True)\r\n",
        "\t#acc = round(result['weighted avg']['f1-score'], 6)\r\n",
        "\tacc = round(f1_score(output_list, target_list, average='micro'), 6)\r\n",
        "\tloss = round(running_loss / len(data_loader.dataset), 6)\r\n",
        "\r\n",
        "\treturn acc, loss"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nP-eieYA5MmY"
      },
      "source": [
        "### 初期値設定\r\n",
        "train.pyでは引数で設定している個所をべた書きで指定する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9i0Pybu35WiY",
        "outputId": "d52de4ee-e374-4b8f-d3a4-0917832000e5"
      },
      "source": [
        "dataset_name         = 'sim_race'\r\n",
        "data_csv             = '../../../../DataSet/_2021-01-04-13-37-29/_2021-01-04-13-37-29.csv'\r\n",
        "model_name           = 'keyboad_test_ResNet18'\r\n",
        "model_ckpt_dir       = './model_0104_2/checkpoints/'\r\n",
        "model_ckpt_path_temp = '/work/experiments/models/checkpoints/{}_{}_epoch={}.pth'\r\n",
        "n_epoch              = 20\r\n",
        "lr                   = 0.1\r\n",
        "test_interval        = 2\r\n",
        "save_model_interval  = 2\r\n",
        "\r\n",
        "\r\n",
        "# Make directory.\r\n",
        "os.makedirs(model_ckpt_dir, exist_ok=True)\r\n",
        "\r\n",
        "print(data_csv)\r\n",
        "# Validate paths.\r\n",
        "assert os.path.exists(data_csv)\r\n",
        "assert os.path.exists(model_ckpt_dir)\r\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "../../../../DataSet/_2021-01-04-13-37-29/_2021-01-04-13-37-29.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHPZ8axO7b_e"
      },
      "source": [
        "### main関数\r\n",
        "Deviceの設定、データロード、モデル設定、オプティマイザーの設定などステップ的に実行する。\r\n",
        "元のtrain.pyから引数部のみ変更した。\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6TEIVJL7kA-",
        "outputId": "85ea2511-217e-4e0d-fef5-ba3cb8d41faf"
      },
      "source": [
        "# Set device.\r\n",
        "print('Setting Device ...')\r\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
        "ROOT_DIR = \"\"\r\n",
        "imgDataset = MyDataset(data_csv, ROOT_DIR, transform=transforms.ToTensor())\r\n",
        "print('done!')\r\n",
        "\r\n",
        "# Load dataset.\r\n",
        "print('Loading dataset...')\r\n",
        "train_data, test_data = train_test_split(imgDataset, test_size=0.2)\r\n",
        "pd.to_pickle(test_data, \"test_data.pkl\")\r\n",
        "del test_data\r\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=20, shuffle=True)\r\n",
        "print('done!')\r\n",
        "\r\n",
        "print('Setting model...')\r\n",
        "# Set a model.\r\n",
        "model = models.resnet18()\r\n",
        "model.train()\r\n",
        "model.fc = torch.nn.Linear(512, 3)\r\n",
        "model = model.to(device)\r\n",
        "print('done!')\r\n",
        "\r\n",
        "print('Setting optimizer...')\r\n",
        "# Set loss function and optimization function.\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = optim.Adam(model.parameters())\r\n",
        "#optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=5e-4)\r\n",
        "print('done!')\r\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting Device ...\n",
            "done!\n",
            "Loading dataset...\n",
            "done!\n",
            "Setting model...\n",
            "done!\n",
            "Setting optimizer...\n",
            "done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqtTgkX69Tqi"
      },
      "source": [
        "### train\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcT4QFux9bNr",
        "outputId": "81509b4a-2dcd-401a-945d-adf089e89965"
      },
      "source": [
        "# Train and test.\r\n",
        "print('Training...')\r\n",
        "for epoch in range(n_epoch):\r\n",
        "  # Train and test a model.\r\n",
        "  train_acc, train_loss = train(model, device, train_loader, criterion, optimizer)\r\n",
        "  \r\n",
        "  # Output score.\r\n",
        "  if(epoch%test_interval == 0):\r\n",
        "    pd.to_pickle(train_data, \"train_data.pkl\")\r\n",
        "    del train_data\r\n",
        "    \r\n",
        "    test_data   = pd.read_pickle(\"test_data.pkl\")\r\n",
        "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=20, shuffle=True)\r\n",
        "    del test_data\r\n",
        "    test_acc, test_loss = test(model, device, test_loader, criterion)\r\n",
        "    del test_loader\r\n",
        "\r\n",
        "    stdout_temp = 'epoch: {:>3}, train acc: {:<8}, train loss: {:<8}, test acc: {:<8}, test loss: {:<8}'\r\n",
        "    print(stdout_temp.format(epoch+1, train_acc, train_loss, test_acc, test_loss))\r\n",
        "\r\n",
        "    train_data = pd.read_pickle(\"train_data.pkl\")\r\n",
        "  else:\t\r\n",
        "    stdout_temp = 'epoch: {:>3}, train acc: {:<8}, train loss: {:<8}' #, test acc: {:<8}, test loss: {:<8}'\r\n",
        "    print(stdout_temp.format(epoch+1, train_acc, train_loss)) #, test_acc, test_loss))\r\n",
        "\r\n",
        "  # Save a model checkpoint.\r\n",
        "  if(epoch%save_model_interval == 0):\r\n",
        "    model_ckpt_path_temp = model_ckpt_dir + '{}_{}_epoch={}.pth'\r\n",
        "    model_ckpt_path = model_ckpt_path_temp.format(dataset_name, model_name, epoch+1)\r\n",
        "    torch.save(model.state_dict(), model_ckpt_path)\r\n",
        "    print('Saved a model checkpoint at {}'.format(model_ckpt_path))\r\n",
        "    print('')\r\n",
        "\r\n",
        "print('done!')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "batch:  10/24 , train acc: 0.6     , train loss: 0.019484\n",
            "batch:  20/24 , train acc: 0.62381 , train loss: 0.035225\n",
            "epoch:   1, train acc: 0.626305, train loss: 0.040336, test acc: 0.416667, test loss: 0.0933  \n",
            "Saved a model checkpoint at ./model_0104_2/checkpoints/sim_race_keyboad_test_ResNet18_epoch=1.pth\n",
            "\n",
            "batch:  10/24 , train acc: 0.645455, train loss: 0.017029\n",
            "batch:  20/24 , train acc: 0.657143, train loss: 0.029981\n",
            "epoch:   2, train acc: 0.655532, train loss: 0.034731\n",
            "batch:  10/24 , train acc: 0.704545, train loss: 0.015162\n",
            "batch:  20/24 , train acc: 0.704762, train loss: 0.030034\n",
            "epoch:   3, train acc: 0.688935, train loss: 0.034798, test acc: 0.466667, test loss: 0.062017\n",
            "Saved a model checkpoint at ./model_0104_2/checkpoints/sim_race_keyboad_test_ResNet18_epoch=3.pth\n",
            "\n",
            "batch:  10/24 , train acc: 0.65    , train loss: 0.016171\n",
            "batch:  20/24 , train acc: 0.67381 , train loss: 0.029299\n",
            "epoch:   4, train acc: 0.672234, train loss: 0.033255\n",
            "batch:  10/24 , train acc: 0.695455, train loss: 0.015349\n",
            "batch:  20/24 , train acc: 0.695238, train loss: 0.028295\n",
            "epoch:   5, train acc: 0.697286, train loss: 0.032965, test acc: 0.55    , test loss: 0.048151\n",
            "Saved a model checkpoint at ./model_0104_2/checkpoints/sim_race_keyboad_test_ResNet18_epoch=5.pth\n",
            "\n",
            "batch:  10/24 , train acc: 0.695455, train loss: 0.014859\n",
            "batch:  20/24 , train acc: 0.683333, train loss: 0.028697\n",
            "epoch:   6, train acc: 0.688935, train loss: 0.032175\n",
            "batch:  10/24 , train acc: 0.740909, train loss: 0.013946\n",
            "batch:  20/24 , train acc: 0.754762, train loss: 0.026235\n",
            "epoch:   7, train acc: 0.74739 , train loss: 0.030763, test acc: 0.591667, test loss: 0.038674\n",
            "Saved a model checkpoint at ./model_0104_2/checkpoints/sim_race_keyboad_test_ResNet18_epoch=7.pth\n",
            "\n",
            "batch:  10/24 , train acc: 0.704545, train loss: 0.015086\n",
            "batch:  20/24 , train acc: 0.75    , train loss: 0.026132\n",
            "epoch:   8, train acc: 0.749478, train loss: 0.030035\n",
            "batch:  10/24 , train acc: 0.722727, train loss: 0.013402\n",
            "batch:  20/24 , train acc: 0.714286, train loss: 0.026348\n",
            "epoch:   9, train acc: 0.720251, train loss: 0.029886, test acc: 0.558333, test loss: 0.044361\n",
            "Saved a model checkpoint at ./model_0104_2/checkpoints/sim_race_keyboad_test_ResNet18_epoch=9.pth\n",
            "\n",
            "batch:  10/24 , train acc: 0.759091, train loss: 0.013106\n",
            "batch:  20/24 , train acc: 0.788095, train loss: 0.02395 \n",
            "epoch:  10, train acc: 0.772443, train loss: 0.028024\n",
            "batch:  10/24 , train acc: 0.759091, train loss: 0.012644\n",
            "batch:  20/24 , train acc: 0.761905, train loss: 0.024623\n",
            "epoch:  11, train acc: 0.764092, train loss: 0.028   , test acc: 0.55    , test loss: 0.049439\n",
            "Saved a model checkpoint at ./model_0104_2/checkpoints/sim_race_keyboad_test_ResNet18_epoch=11.pth\n",
            "\n",
            "batch:  10/24 , train acc: 0.818182, train loss: 0.010262\n",
            "batch:  20/24 , train acc: 0.790476, train loss: 0.023107\n",
            "epoch:  12, train acc: 0.789144, train loss: 0.026512\n",
            "batch:  10/24 , train acc: 0.745455, train loss: 0.012332\n",
            "batch:  20/24 , train acc: 0.75    , train loss: 0.024379\n",
            "epoch:  13, train acc: 0.745303, train loss: 0.028467, test acc: 0.45    , test loss: 0.068548\n",
            "Saved a model checkpoint at ./model_0104_2/checkpoints/sim_race_keyboad_test_ResNet18_epoch=13.pth\n",
            "\n",
            "batch:  10/24 , train acc: 0.736364, train loss: 0.013064\n",
            "batch:  20/24 , train acc: 0.769048, train loss: 0.022988\n",
            "epoch:  14, train acc: 0.757829, train loss: 0.027932\n",
            "batch:  10/24 , train acc: 0.827273, train loss: 0.009858\n",
            "batch:  20/24 , train acc: 0.807143, train loss: 0.021171\n",
            "epoch:  15, train acc: 0.803758, train loss: 0.024845, test acc: 0.608333, test loss: 0.046259\n",
            "Saved a model checkpoint at ./model_0104_2/checkpoints/sim_race_keyboad_test_ResNet18_epoch=15.pth\n",
            "\n",
            "batch:  10/24 , train acc: 0.813636, train loss: 0.010938\n",
            "batch:  20/24 , train acc: 0.792857, train loss: 0.021533\n",
            "epoch:  16, train acc: 0.793319, train loss: 0.024727\n",
            "batch:  10/24 , train acc: 0.831818, train loss: 0.01055 \n",
            "batch:  20/24 , train acc: 0.838095, train loss: 0.019095\n",
            "epoch:  17, train acc: 0.824635, train loss: 0.022258, test acc: 0.566667, test loss: 0.045067\n",
            "Saved a model checkpoint at ./model_0104_2/checkpoints/sim_race_keyboad_test_ResNet18_epoch=17.pth\n",
            "\n",
            "batch:  10/24 , train acc: 0.872727, train loss: 0.007214\n",
            "batch:  20/24 , train acc: 0.835714, train loss: 0.017537\n",
            "epoch:  18, train acc: 0.830898, train loss: 0.0212  \n",
            "batch:  10/24 , train acc: 0.863636, train loss: 0.008028\n",
            "batch:  20/24 , train acc: 0.845238, train loss: 0.016526\n",
            "epoch:  19, train acc: 0.843424, train loss: 0.01936 , test acc: 0.55    , test loss: 0.066603\n",
            "Saved a model checkpoint at ./model_0104_2/checkpoints/sim_race_keyboad_test_ResNet18_epoch=19.pth\n",
            "\n",
            "batch:  10/24 , train acc: 0.9     , train loss: 0.005999\n",
            "batch:  20/24 , train acc: 0.87381 , train loss: 0.013954\n",
            "epoch:  20, train acc: 0.878914, train loss: 0.015486\n",
            "done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZFByj074Pww"
      },
      "source": [
        "## train.pyの実行(上記でエラーが発生する場合)\r\n",
        "train.pyを実行すれば動く。迷ったら以下のコードでtrain.pyを直接実行する。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miBQl5kHDJ6e"
      },
      "source": [
        "Train.pyの修正箇所：\r\n",
        "- CSVファイルにtrain_dataのパスがべた書きされているので、変更する必要あり。\r\n",
        "-train.py:76行目\r\n",
        "```\r\n",
        "model_ckpt_path = args.model_ckpt_path_temp.format(args.dataset_name, args.model_name, epoch+1)\r\n",
        "```\r\n",
        "を以下に変更。モデル保存パスを引数から反映させるようにする。\r\n",
        "```\r\n",
        "model_ckpt_path_temp = args.model_ckpt_dir + '{}_{}_epoch={}.pth'\r\n",
        "model_ckpt_path = model_ckpt_path_temp.format(args.dataset_name, args.model_name, epoch+1)\r\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5u3c6qiEyKX"
      },
      "source": [
        "# !time python train.py --n_epoch 20 --data_csv \"../../../../DataSet/_2021-01-02-11-37-17/_2021-01-02-11-37-17.csv\" --model_name sample_model --model_ckpt_dir \"./model_0104/checkpoints/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43EDYyStg13B"
      },
      "source": [
        "## 学習モデルの軽量化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1_U5K8cEzb6"
      },
      "source": [
        "環境うまく動かず失敗。jetson nanoのローカル環境にコピーしてから実行している。"
      ]
    }
  ]
}